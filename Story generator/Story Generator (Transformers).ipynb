{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "331cdb7c-9a31-4a26-b82c-3887d5a0cc93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e458697e-130e-49ec-bc9b-89dd94cdd990",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\r\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\r\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/12.8 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.2/12.8 MB\u001B[0m \u001B[31m7.0 MB/s\u001B[0m eta \u001B[36m0:00:02\u001B[0m\r\u001B[2K     \u001B[91m━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.7/12.8 MB\u001B[0m \u001B[31m10.7 MB/s\u001B[0m eta \u001B[36m0:00:02\u001B[0m\r\u001B[2K     \u001B[91m━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/12.8 MB\u001B[0m \u001B[31m12.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/12.8 MB\u001B[0m \u001B[31m14.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/12.8 MB\u001B[0m \u001B[31m16.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.7/12.8 MB\u001B[0m \u001B[31m18.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.9/12.8 MB\u001B[0m \u001B[31m20.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.2/12.8 MB\u001B[0m \u001B[31m22.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.8/12.8 MB\u001B[0m \u001B[31m24.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━\u001B[0m \u001B[32m9.7/12.8 MB\u001B[0m \u001B[31m27.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m11.9/12.8 MB\u001B[0m \u001B[31m39.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m44.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m35.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n\u001B[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /databricks/python3/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\r\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\r\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\r\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\r\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.28.1)\r\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\r\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\r\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.64.1)\r\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\r\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\r\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\r\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\r\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\r\nRequirement already satisfied: thinc<8.3.0,>=8.1.8 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\r\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\r\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (65.6.3)\r\nRequirement already satisfied: numpy>=1.19.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.5)\r\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\r\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\r\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.6)\r\nRequirement already satisfied: typing-extensions>=4.2.0 in /databricks/python3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.4.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.12.7)\r\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\r\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\r\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.14)\r\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /databricks/python3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\r\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /databricks/python3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\r\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /databricks/python3/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\r\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /databricks/python3/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\r\n\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\nYou can now load the package via spacy.load('en_core_web_sm')\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89b2ea6d-d02d-4697-84f9-49f88cd6ad1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def find_part_of_speech(story):\n",
    "    tokens_spacy = nlp(story)\n",
    "    pos_tags = [(token.text, token.pos_) for token in tokens_spacy]\n",
    "    Part_of_speech_dict = {}\n",
    "    for token, pos in pos_tags:\n",
    "        if pos not in Part_of_speech_dict:\n",
    "            Part_of_speech_dict[pos] = []\n",
    "        Part_of_speech_dict[pos].append(token)\n",
    "        \n",
    "    print(\"c. Find all Part-of-speeches in the generated story\")\n",
    "    for i in Part_of_speech_dict:\n",
    "        print(i,\": \",Part_of_speech_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b917ebd4-d450-4694-bb26-5c717192e351",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: transformers in /databricks/python3/lib/python3.10/site-packages (4.36.1)\nRequirement already satisfied: torch in /databricks/python3/lib/python3.10/site-packages (2.0.1+cpu)\nRequirement already satisfied: datasets in /databricks/python3/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from transformers) (2022.7.9)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.19.4)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from transformers) (23.2)\nRequirement already satisfied: tqdm>=4.27 in /databricks/python3/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: safetensors>=0.3.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: sympy in /databricks/python3/lib/python3.10/site-packages (from torch) (1.11.1)\nRequirement already satisfied: typing-extensions in /databricks/python3/lib/python3.10/site-packages (from torch) (4.4.0)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.10/site-packages (from torch) (2.8.4)\nRequirement already satisfied: aiohttp in /databricks/python3/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /databricks/python3/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: xxhash in /databricks/python3/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.10/site-packages (from datasets) (1.5.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /databricks/python3/lib/python3.10/site-packages (from datasets) (8.0.0)\nRequirement already satisfied: pyarrow-hotfix in /databricks/python3/lib/python3.10/site-packages (from datasets) (0.5)\nRequirement already satisfied: multiprocess in /databricks/python3/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries \n",
    "%pip install transformers torch datasets\n",
    "\n",
    "# Import required modules\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b41f5d68-acd6-40cb-86f9-663de9504423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "async def main():\n",
    "  try:\n",
    "\n",
    "        while True:\n",
    "            print('Story Generator')\n",
    "            print('Type quit to finish')\n",
    "            user_input = input('Enter the Beginning of the story')\n",
    "\n",
    "            if user_input.lower() == 'quit':\n",
    "                print('Exiting program...')\n",
    "                break\n",
    "\n",
    "            file = open(file=\"function.py\", encoding=\"utf8\").read()\n",
    "\n",
    "            prompt = user_input + file\n",
    "            generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "            # Generate text\n",
    "            prompt = user_input\n",
    "            result = generator(prompt, max_length=100, num_return_sequences=1)\n",
    "\n",
    "            # Display generated text\n",
    "            print(\"a. A story of 100 words about the prompt\")\n",
    "            print(\"Generated Text:\", result[0]['generated_text'])\n",
    "            \n",
    "            tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            inputs = tokenizer(result[0]['generated_text'], return_tensors='pt', truncation=True, max_length=512)\n",
    "            print(\"b. This story should be represented in a vector/embeddings format\")\n",
    "            print(\"Tokenized Sample:\", inputs)\n",
    "\n",
    "            find_part_of_speech(result[0]['generated_text'])\n",
    "\n",
    "\n",
    "  except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faeb8e7c-9653-40f6-96ee-2e26fb2401a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story Generator\nType quit to finish\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter the Beginning of the story The old tortoise in the jungle was"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. A story of 100 words about the prompt\nGenerated Text: The old tortoise in the jungle was an old man with the shape of a big tree on his back, a big tree in his mouth. His head was like an old cat's. Like a great beast. All these things were in that body, and he was an old man. Only his nose looked right.\n influences : a bony form of cat (usually a mama or wolf, except in the case of dogs, when the mother is pregnant, they would often pick up on\nb. This story should be represented in a vector/embeddings format\nTokenized Sample: {'input_ids': tensor([[  464,  1468,  7619, 25678,   287,   262, 20712,   373,   281,  1468,\n           582,   351,   262,  5485,   286,   257,  1263,  5509,   319,   465,\n           736,    11,   257,  1263,  5509,   287,   465,  5422,    13,  2399,\n          1182,   373,   588,   281,  1468,  3797,   338,    13,  4525,   257,\n          1049, 13824,    13,  1439,   777,  1243,   547,   287,   326,  1767,\n            11,   290,   339,   373,   281,  1468,   582,    13,  5514,   465,\n          9686,  3114,   826,    13,   198, 16717,  1058,   257,   275,  1647,\n          1296,   286,  3797,   357, 23073,   257,   285,  1689,   393, 17481,\n            11,  2845,   287,   262,  1339,   286,  6844,    11,   618,   262,\n          2802,   318, 10423,    11,   484,   561,  1690,  2298,   510,   319]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1]])}\nc. Find all Part-of-speeches in the generated story\nDET :  ['The', 'the', 'an', 'the', 'a', 'a', 'an', 'a', 'All', 'these', 'that', 'an', 'a', 'a', 'the', 'the']\nADJ :  ['old', 'old', 'big', 'big', 'old', 'great', 'old', 'right', 'pregnant']\nNOUN :  ['tortoise', 'jungle', 'man', 'shape', 'tree', 'back', 'tree', 'mouth', 'head', 'cat', 'beast', 'things', 'body', 'man', 'nose', 'influences', 'bony', 'form', 'cat', 'mama', 'wolf', 'case', 'dogs', 'mother']\nADP :  ['in', 'with', 'of', 'on', 'in', 'like', 'Like', 'in', 'of', 'in', 'of', 'up', 'on']\nAUX :  ['was', 'was', 'were', 'was', 'is', 'would']\nPRON :  ['his', 'his', 'His', 'he', 'his', 'they']\nPUNCT :  [',', '.', '.', '.', ',', '.', '.', ':', '(', ',', ',', ',']\nPART :  [\"'s\"]\nCCONJ :  ['and', 'or']\nADV :  ['Only', 'usually', 'often']\nVERB :  ['looked', 'pick']\nSPACE :  ['\\n ']\nSCONJ :  ['except', 'when']\nStory Generator\nType quit to finish\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter the Beginning of the story quit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting program...\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "In Class Assignment Nov 22",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
